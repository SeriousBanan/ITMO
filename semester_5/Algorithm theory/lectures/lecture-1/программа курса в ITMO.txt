


Описательные статистики. 
Квантили, квартили. Гистограммы. Ядерные оценки плотности. Ящики с усами. Выбросы. Медиана и среднее арифметическое как типичные наблюдения. Диаграмма рассеивания. Матрица диаграмм рассеивания. Столбиковая и круговая диаграмма.


Кластеризация. Иерархический кластерный анализ. 
Кластер, расстояния между объектами, расстояния между кластерами. Алгоритм построения дендрограммы. Каменистая осыпь/локоть. Стандартизация данных. Типичные ошибки при подготовке данных. Интрепретация результатов.


Кластеризация. Метод к-средних. 


Проверка статистических гипотез (теоретическое введение).
Гипотезы согласия, однородности, независимости, гипотезы о параметрах распределения.
Ошибки первого и второго рода, р-значение и уровень значимости, алгоритм проверки статистической гипотезы и интерпретация результатов. Гипотеза о нормальности распределения. Критерии Шапиро-Уилка и Колмогорова-Смирнова. Несущественные отклонения от нормальности. Сравнение выборок. Независимые и парные выборки. Выбор между t-критерием Стъюдента, критерием Манна-Уитни-Вилкоксона и критерием Муда. Разновидности t-критериев Стъюдента и сравнение дисперсий. Визуализация при сравнениях. Односторонние и двусторонние тесты.
Независимость. Коэффициенты корреляции Пирсона, Кендалла и Спирмена, типичные ошибки при изучении связи между двумя явлениями. Визуальная проверка выводов.


Проверка статистических гипотез (процедуры Python).

Критерий Шапиро-Уилка. Критерий Манна-Уитни-Вилкоксона. t-критерий Стъюдента. Критерий Флигнера-Килина.

Независимые и парные выборки. Критерий хи-квадрат. Критерий Пирсона.


A/B тестирование. Тест для пропорций.


Линейный регрессионный анализ. 
Модель, интерпретация оценок коэффициентов, множественный коэффициент детерминации. Интерпретация множественного коэффициента детерминации, ограничения на область его применения. Выявление наиболее значимых предикторов и оценка вклада каждого предиктора. Алгоритмы корректировки построенных моделей. Коллинеарность.


Прогнозирование на основе регрессионной модели с сезонными индикаторными (фиктивными, структурными) переменными. Тренд, сезонные составляющие, смена характера ряда, выбросы. Логарифмирование – прием для преобразования мультипликативной сезонности в аддитивную.
Индикаторные переменные. Интервения
Переобучение.
Случай нескольких сезонных составляющих.
Сокращение числа сезонных составляющих.

Логистическая регрессия (Logistic regression).

Ядерная регрессия.


Распознавание образов/классификация/машинное обучение.
Параметры модели, внутренние и внешние.
Критерии качества. Обучающая и тестовая выборки.


Деревья классификации CART. 
Геометрическое представление. Представление в виде набора логических правил. Представление в виде дерева. Узлы, родители и потомки, конечные узлы. Пороговые значения. Меры чистота узла (impurity measures): джини, энтропия, ошибки классификации. Правила останоки обучения дерева. Информативность переменных.
Деревья классификации в задачах регрессии.


Bagging. Случайные леса. 
Ключевые параметры модели. Out-of-bag error. Информативность переменных. Анализ несбалансированных выборок. Определение числа деревьев.


Boosting. Gradient boosting machine. 
Ключевые параметры модели.


Boosting. XGboost.
Теоретическое обоснование метода. Несбалансированные выборки. Подбор параметров в XGboost.
Информативность переменных (Importance). Подбор параметров в XGboost. GridSearch для подбора параметров. 
Стекинг.


Нейронные сети (теоретическое введение).
Модель нейрона. Активационная функция. Сети прямого распространения (FeedForward Neural Network). Архитектура нейронной сети. Коннективизм (connectionism). 
Обучение нейронной сети. Обратное распространение ошибки. Метод скорейшего спуска (Gradient descent) и его обобщения. Эпохи и batch'и. 


Нейронные сети (обучение инструментами Python).
Введение в Keras и TensorFlow. Инициализация весов нейронной сети. Стандартизация данных предотвращает насыщение. Обучение нейронной сети прямого распространения. Оптимизация (optimizers)в Keras. Формулы для поправок весов при обучении нейронной сети. 
Критерии качества в Keras. Инициализация весов нейронной сети в Keras. 


Нейронные сети для прогнозирования. 
Сведение задачи прогнозирования к регрессионной задаче. Прогнозирование рядов с сезонной составляющей.


Deep Learning.
Распознавание изображений. Каскад Хаара для выделения лица на картинке.
Свертки. Сверточные слои (convolution layer). Padding. Stride. Pooling.
Dropout и декорреляция. Дообучение нейронных сетей. Augmentaiton. VGG-16 архитектура нейронной сети. 



Регуляризация. 
Назначение регуляризации. Регуляризация в линейном регрессионном анализе. Нормальные уравнения линейного регрессионного анализа. Добавление регуляризационного слагаемого в нормальные уравнения. Особая роль свободного члена. Пример: аппроксимация точек многочленом. Выборка валидации. Варианты регуляризационного слагаемого (ridge regression, lasso, elastic net). Почему Lasso позволяет сократить число предикторов. 


Факторный анализ. 
Задачи, решаемые с помощью факторного анализа. Математические модели анализа главных компонент и факторного анализа. Интерпретация факторов. Пример проведения факторного анализа в Python. Факторные нагрузки, факторные метки, их интерпретация. Вращения факторов. 


SVD разложение.
Математические модель SVD разложения. SVD разложение и анализ главных компонент. SVD разложение как основа латентно — семантического анализа (LSA). SVD разложение матрицы данных, содержащей пропуски. Метод Simon'a Funk'a Регуляризация в методе Simon'a Funk'a. SVD разложение при построении рекомендательной системы.
Особенности применения SVD разложения (Singular Value Decomposition) для данных с большим числом пропусков. 


Калибровка классификаторов. 
Изотоническая регрессия (isotonic regression). Калибровка Платта (Platt calibration).


Анализ несбалансированных выборок. 
Accuracy, precision, recall, F1. ROC кривая (ROC curve) для определения порогового значения. ROC кривая (ROC curve) для сравнения классификаторов. Area under curve (AUC). 



Прогнозирование.
Сезонная декомпозиция.
Экспоненциальное сглаживание.
ARIMA. SARIMAX.
Prophet.
Применение методов машинного обучения для прогнозирования.
Особенности формирования тестовой выборки.




